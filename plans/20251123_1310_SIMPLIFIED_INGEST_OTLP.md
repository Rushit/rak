# Simplified Telemetry Ingestion Service Using OTLP gRPC

**Date**: 2025-11-23 13:10  
**Status**: ğŸ¯ Simplified Design  
**Replaces**: Complex custom handlers with OpenTelemetry proto-generated code

---

## ğŸ¯ Key Simplification

**Use OpenTelemetry's official proto definitions** to generate gRPC server code automatically:

âœ… **Standard OTLP protocol** (no custom formats)  
âœ… **Auto-generated code** from `.proto` files (via tonic/prost)  
âœ… **100% compatible** with any OTLP client  
âœ… **Less code to maintain** (proto definitions are stable)  
âœ… **Support for traces, metrics, AND logs** out of the box

---

## ğŸ—ï¸ Simplified Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RAK Agents (OTLP Clients)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ OTLP/gRPC (Port 4317)
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         rak-ingest (OTLP gRPC Server)                   â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Auto-generated from OpenTelemetry Proto         â”‚  â”‚
â”‚  â”‚  (using tonic + prost)                           â”‚  â”‚
â”‚  â”‚                                                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚
â”‚  â”‚  â”‚ TraceService   â”‚  â”‚ MetricsService â”‚         â”‚  â”‚
â”‚  â”‚  â”‚   Server       â”‚  â”‚     Server     â”‚         â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚
â”‚  â”‚          â”‚                    â”‚                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚             â”‚                    â”‚                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚    â”‚  OTLP Message Converter               â”‚          â”‚
â”‚    â”‚  (ResourceSpans -> ClickHouse Row)    â”‚          â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚             â”‚                                          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚    â”‚  Batch Buffer                         â”‚          â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ClickHouse Cluster                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Simplified Project Structure

```
crates/rak-ingest/
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ build.rs                    # Proto compilation
â”œâ”€â”€ proto/
â”‚   â””â”€â”€ opentelemetry/          # Git submodule or vendored
â”‚       â”œâ”€â”€ trace/
â”‚       â”‚   â””â”€â”€ v1/
â”‚       â”‚       â””â”€â”€ trace.proto
â”‚       â”œâ”€â”€ metrics/
â”‚       â”‚   â””â”€â”€ v1/
â”‚       â”‚       â””â”€â”€ metrics.proto
â”‚       â””â”€â”€ logs/
â”‚           â””â”€â”€ v1/
â”‚               â””â”€â”€ logs.proto
â””â”€â”€ src/
    â”œâ”€â”€ main.rs                 # Entry point
    â”œâ”€â”€ lib.rs
    â”œâ”€â”€ config.rs               # Configuration
    â”œâ”€â”€ otlp/
    â”‚   â”œâ”€â”€ mod.rs
    â”‚   â”œâ”€â”€ trace_service.rs    # Implement TraceService trait
    â”‚   â”œâ”€â”€ metrics_service.rs  # Implement MetricsService trait
    â”‚   â””â”€â”€ converter.rs        # OTLP -> ClickHouse conversion
    â”œâ”€â”€ batch/
    â”‚   â”œâ”€â”€ mod.rs
    â”‚   â””â”€â”€ buffer.rs           # Batch buffer (same as before)
    â”œâ”€â”€ storage/
    â”‚   â”œâ”€â”€ mod.rs
    â”‚   â””â”€â”€ clickhouse.rs       # ClickHouse client (same as before)
    â””â”€â”€ generated/              # Auto-generated by build.rs
        â””â”€â”€ opentelemetry.rs    # Proto-generated code
```

---

## ğŸ”§ Implementation

### 1. Cargo.toml Dependencies

```toml
[package]
name = "rak-ingest"
version = "0.1.0"
edition = "2021"

[dependencies]
# gRPC server
tonic = "0.10"
prost = "0.12"
tokio = { version = "1.35", features = ["full"] }

# OpenTelemetry proto (auto-generated)
opentelemetry-proto = { version = "0.4", features = ["gen-tonic"] }

# ClickHouse
clickhouse = "0.11"

# Batching & async
tokio-stream = "0.1"
futures = "0.3"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }

# Error handling
anyhow = "1.0"
thiserror = "1.0"

[build-dependencies]
tonic-build = "0.10"
```

---

### 2. build.rs (Proto Compilation)

```rust
fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Note: opentelemetry-proto crate already provides compiled protos
    // We don't need to compile them ourselves!
    // This build.rs is only needed if we add custom proto definitions
    
    Ok(())
}
```

**Even simpler**: Use the `opentelemetry-proto` crate which already has generated code!

---

### 3. OTLP Trace Service Implementation

**File**: `crates/rak-ingest/src/otlp/trace_service.rs`

```rust
use opentelemetry_proto::tonic::collector::trace::v1::{
    trace_service_server::TraceService,
    ExportTraceServiceRequest,
    ExportTraceServiceResponse,
};
use tonic::{Request, Response, Status};
use std::sync::Arc;
use crate::batch::BatchBuffer;
use crate::otlp::converter::convert_resource_spans;

#[derive(Clone)]
pub struct OtlpTraceService {
    batch_buffer: Arc<BatchBuffer>,
}

impl OtlpTraceService {
    pub fn new(batch_buffer: Arc<BatchBuffer>) -> Self {
        Self { batch_buffer }
    }
}

#[tonic::async_trait]
impl TraceService for OtlpTraceService {
    async fn export(
        &self,
        request: Request<ExportTraceServiceRequest>,
    ) -> Result<Response<ExportTraceServiceResponse>, Status> {
        let req = request.into_inner();
        
        tracing::debug!(
            "Received trace export request with {} resource spans",
            req.resource_spans.len()
        );
        
        // Convert OTLP format to our internal format
        for resource_spans in req.resource_spans {
            let spans = convert_resource_spans(resource_spans)
                .map_err(|e| Status::internal(format!("Conversion error: {}", e)))?;
            
            // Add to batch buffer
            for span in spans {
                self.batch_buffer.add_span(span).await;
            }
        }
        
        // Return success response
        Ok(Response::new(ExportTraceServiceResponse {
            partial_success: None,
        }))
    }
}
```

---

### 4. OTLP Metrics Service Implementation

**File**: `crates/rak-ingest/src/otlp/metrics_service.rs`

```rust
use opentelemetry_proto::tonic::collector::metrics::v1::{
    metrics_service_server::MetricsService,
    ExportMetricsServiceRequest,
    ExportMetricsServiceResponse,
};
use tonic::{Request, Response, Status};
use std::sync::Arc;
use crate::batch::BatchBuffer;
use crate::otlp::converter::convert_resource_metrics;

#[derive(Clone)]
pub struct OtlpMetricsService {
    batch_buffer: Arc<BatchBuffer>,
}

impl OtlpMetricsService {
    pub fn new(batch_buffer: Arc<BatchBuffer>) -> Self {
        Self { batch_buffer }
    }
}

#[tonic::async_trait]
impl MetricsService for OtlpMetricsService {
    async fn export(
        &self,
        request: Request<ExportMetricsServiceRequest>,
    ) -> Result<Response<ExportMetricsServiceResponse>, Status> {
        let req = request.into_inner();
        
        tracing::debug!(
            "Received metrics export request with {} resource metrics",
            req.resource_metrics.len()
        );
        
        // Convert OTLP format to our internal format
        for resource_metrics in req.resource_metrics {
            let metrics = convert_resource_metrics(resource_metrics)
                .map_err(|e| Status::internal(format!("Conversion error: {}", e)))?;
            
            // Add to batch buffer
            for metric in metrics {
                self.batch_buffer.add_metric(metric).await;
            }
        }
        
        // Return success response
        Ok(Response::new(ExportMetricsServiceResponse {
            partial_success: None,
        }))
    }
}
```

---

### 5. OTLP Converter (Proto -> Internal Format)

**File**: `crates/rak-ingest/src/otlp/converter.rs`

```rust
use opentelemetry_proto::tonic::trace::v1::{ResourceSpans, Span as OtlpSpan};
use opentelemetry_proto::tonic::metrics::v1::ResourceMetrics;
use anyhow::Result;
use crate::batch::{Span, Metric};

/// Convert OTLP ResourceSpans to our internal Span format
pub fn convert_resource_spans(resource_spans: ResourceSpans) -> Result<Vec<Span>> {
    let mut spans = Vec::new();
    
    // Extract resource attributes (service.name, etc.)
    let service_name = resource_spans
        .resource
        .as_ref()
        .and_then(|r| {
            r.attributes.iter().find(|attr| attr.key == "service.name")
        })
        .and_then(|attr| attr.value.as_ref())
        .and_then(|v| v.string_value.as_ref())
        .map(|s| s.to_string())
        .unwrap_or_else(|| "unknown".to_string());
    
    // Process each scope (instrumentation library)
    for scope_spans in resource_spans.scope_spans {
        // Process each span
        for otlp_span in scope_spans.spans {
            let span = convert_span(otlp_span, &service_name)?;
            spans.push(span);
        }
    }
    
    Ok(spans)
}

/// Convert a single OTLP Span to our internal format
fn convert_span(otlp_span: OtlpSpan, service_name: &str) -> Result<Span> {
    // Convert trace_id and span_id from bytes to hex string
    let trace_id = hex::encode(&otlp_span.trace_id);
    let span_id = hex::encode(&otlp_span.span_id);
    let parent_span_id = if !otlp_span.parent_span_id.is_empty() {
        Some(hex::encode(&otlp_span.parent_span_id))
    } else {
        None
    };
    
    // Extract timestamps (nanoseconds since epoch)
    let timestamp = otlp_span.start_time_unix_nano as i64;
    let duration_ns = otlp_span.end_time_unix_nano - otlp_span.start_time_unix_nano;
    
    // Extract attributes
    let mut attributes_map = serde_json::Map::new();
    let mut invocation_id = String::new();
    let mut session_id = String::new();
    let mut agent_name = String::new();
    let mut llm_model = String::new();
    let mut tool_name = String::new();
    
    for attr in &otlp_span.attributes {
        if let Some(value) = &attr.value {
            let key = &attr.key;
            let val = extract_attribute_value(value);
            
            // Extract known attributes
            match key.as_str() {
                "invocation_id" | "gcp.vertex.agent.invocation_id" => {
                    invocation_id = val.as_str().unwrap_or("").to_string();
                }
                "session_id" | "gcp.vertex.agent.session_id" => {
                    session_id = val.as_str().unwrap_or("").to_string();
                }
                "agent.name" => {
                    agent_name = val.as_str().unwrap_or("").to_string();
                }
                "gen_ai.request.model" => {
                    llm_model = val.as_str().unwrap_or("").to_string();
                }
                "gen_ai.tool.name" => {
                    tool_name = val.as_str().unwrap_or("").to_string();
                }
                _ => {}
            }
            
            attributes_map.insert(key.clone(), val);
        }
    }
    
    // Extract resource attributes (CPU, memory)
    let resource_cpu_micros = attributes_map
        .get("resource.cpu.micros")
        .and_then(|v| v.as_u64())
        .unwrap_or(0);
    
    let resource_memory_bytes = attributes_map
        .get("resource.memory.bytes")
        .and_then(|v| v.as_u64())
        .unwrap_or(0);
    
    let resource_memory_peak = attributes_map
        .get("resource.memory.peak")
        .and_then(|v| v.as_u64())
        .unwrap_or(0);
    
    // Determine span kind and status
    let span_kind = match otlp_span.kind {
        1 => "INTERNAL",
        2 => "SERVER",
        3 => "CLIENT",
        4 => "PRODUCER",
        5 => "CONSUMER",
        _ => "UNSPECIFIED",
    }.to_string();
    
    let status_code = otlp_span.status.as_ref()
        .map(|s| match s.code {
            0 => "UNSET",
            1 => "OK",
            2 => "ERROR",
            _ => "UNSET",
        })
        .unwrap_or("UNSET")
        .to_string();
    
    let status_message = otlp_span.status
        .as_ref()
        .map(|s| s.message.clone())
        .unwrap_or_default();
    
    Ok(Span {
        trace_id,
        span_id,
        parent_span_id,
        timestamp,
        duration_ns,
        service_name: service_name.to_string(),
        span_name: otlp_span.name,
        span_kind,
        status_code,
        status_message,
        invocation_id,
        session_id,
        agent_name,
        llm_model,
        tool_name,
        resource_cpu_micros,
        resource_memory_bytes,
        resource_memory_peak,
        attributes: serde_json::to_string(&attributes_map)?,
    })
}

/// Extract value from OTLP AnyValue
fn extract_attribute_value(value: &opentelemetry_proto::tonic::common::v1::AnyValue) -> serde_json::Value {
    use opentelemetry_proto::tonic::common::v1::any_value::Value;
    
    match &value.value {
        Some(Value::StringValue(s)) => serde_json::Value::String(s.clone()),
        Some(Value::BoolValue(b)) => serde_json::Value::Bool(*b),
        Some(Value::IntValue(i)) => serde_json::Value::Number((*i).into()),
        Some(Value::DoubleValue(d)) => {
            serde_json::Number::from_f64(*d)
                .map(serde_json::Value::Number)
                .unwrap_or(serde_json::Value::Null)
        }
        Some(Value::ArrayValue(arr)) => {
            let values: Vec<_> = arr.values.iter()
                .map(extract_attribute_value)
                .collect();
            serde_json::Value::Array(values)
        }
        Some(Value::KvlistValue(kv)) => {
            let mut map = serde_json::Map::new();
            for item in &kv.values {
                if let Some(v) = &item.value {
                    map.insert(item.key.clone(), extract_attribute_value(v));
                }
            }
            serde_json::Value::Object(map)
        }
        _ => serde_json::Value::Null,
    }
}

/// Convert OTLP ResourceMetrics to our internal Metric format
pub fn convert_resource_metrics(resource_metrics: ResourceMetrics) -> Result<Vec<Metric>> {
    let mut metrics = Vec::new();
    
    // Extract service name
    let service_name = resource_metrics
        .resource
        .as_ref()
        .and_then(|r| {
            r.attributes.iter().find(|attr| attr.key == "service.name")
        })
        .and_then(|attr| attr.value.as_ref())
        .and_then(|v| v.string_value.as_ref())
        .map(|s| s.to_string())
        .unwrap_or_else(|| "unknown".to_string());
    
    // Process each scope
    for scope_metrics in resource_metrics.scope_metrics {
        for metric_data in scope_metrics.metrics {
            // Convert based on metric type
            // (implementation depends on metric type: sum, gauge, histogram, etc.)
            // ... see detailed implementation below
        }
    }
    
    Ok(metrics)
}
```

---

### 6. Main Server Setup

**File**: `crates/rak-ingest/src/main.rs`

```rust
use anyhow::Result;
use opentelemetry_proto::tonic::collector::trace::v1::trace_service_server::TraceServiceServer;
use opentelemetry_proto::tonic::collector::metrics::v1::metrics_service_server::MetricsServiceServer;
use rak_ingest::{
    config::IngestConfig,
    otlp::{OtlpTraceService, OtlpMetricsService},
    batch::BatchBuffer,
    storage::ClickHouseStorage,
};
use std::sync::Arc;
use tonic::transport::Server;
use tracing::info;

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize logging
    tracing_subscriber::fmt()
        .with_env_filter(tracing_subscriber::EnvFilter::from_default_env())
        .json()
        .init();
    
    // Load configuration
    let config = IngestConfig::from_file("config.toml")?;
    
    info!("Starting rak-ingest OTLP server");
    info!("ClickHouse: {}", config.clickhouse.url);
    info!("Listening on: 0.0.0.0:{}", config.otlp_port);
    
    // Initialize storage
    let storage = Arc::new(ClickHouseStorage::new(&config.clickhouse).await?);
    
    // Initialize batch buffer
    let batch_buffer = Arc::new(BatchBuffer::new(
        config.batch_size,
        config.batch_timeout,
        storage.clone(),
    ));
    
    // Start background flush task
    batch_buffer.start_flusher().await;
    
    // Create OTLP services
    let trace_service = OtlpTraceService::new(batch_buffer.clone());
    let metrics_service = OtlpMetricsService::new(batch_buffer.clone());
    
    // Build gRPC server
    let addr = format!("0.0.0.0:{}", config.otlp_port).parse()?;
    
    info!("OTLP gRPC server listening on {}", addr);
    
    Server::builder()
        .add_service(TraceServiceServer::new(trace_service))
        .add_service(MetricsServiceServer::new(metrics_service))
        .serve(addr)
        .await?;
    
    Ok(())
}
```

---

### 7. Simplified Configuration

**File**: `config.toml`

```toml
[server]
# Single OTLP gRPC port (standard port)
otlp_port = 4317

# Batch configuration
batch_size = 1000
batch_timeout_seconds = 10

[clickhouse]
url = "http://localhost:8123"
user = "default"
password = ""
database = "telemetry"
max_connections = 10
```

---

### 8. Client Configuration (rak-telemetry)

**File**: `crates/rak-telemetry/src/exporters.rs` (updated)

```rust
use opentelemetry_otlp::WithExportConfig;
use opentelemetry_sdk::trace::TracerProvider;

pub fn create_otlp_exporter(endpoint: &str) -> Result<TracerProvider> {
    let exporter = opentelemetry_otlp::new_exporter()
        .tonic()
        .with_endpoint(endpoint);  // e.g., "http://localhost:4317"
    
    let tracer_provider = opentelemetry_otlp::new_pipeline()
        .tracing()
        .with_exporter(exporter)
        .install_batch(opentelemetry_sdk::runtime::Tokio)?;
    
    Ok(tracer_provider)
}
```

**Client config.toml**:
```toml
[telemetry.tracing.otlp]
endpoint = "http://localhost:4317"  # Points to rak-ingest
```

---

## ğŸ“Š ClickHouse Schema (Same as Before)

The ClickHouse schema remains the same - we're just changing how data arrives:

```sql
CREATE TABLE spans (
    trace_id FixedString(32),
    span_id FixedString(16),
    parent_span_id FixedString(16),
    timestamp DateTime64(9, 'UTC'),
    duration_ns UInt64,
    service_name LowCardinality(String),
    span_name LowCardinality(String),
    -- ... all other fields
) ENGINE = ReplicatedMergeTree()
PARTITION BY toYYYYMMDD(timestamp)
ORDER BY (service_name, timestamp, trace_id);
```

---

## âœ… Benefits of This Approach

### 1. **Standard Protocol**
- Uses official OTLP gRPC (port 4317)
- Works with ANY OTLP client (Rust, Go, Python, Java, etc.)
- Compatible with OpenTelemetry Collector

### 2. **Less Code**
```
Before: ~2500 lines (custom HTTP + gRPC handlers)
After:  ~800 lines (implement trait + converter)
```

### 3. **Auto-Generated Code**
```rust
// This is auto-generated by opentelemetry-proto crate:
pub trait TraceService {
    async fn export(...) -> Result<Response, Status>;
}

// We just implement it!
impl TraceService for OtlpTraceService {
    async fn export(...) -> Result<Response, Status> {
        // Our logic here
    }
}
```

### 4. **Future-Proof**
- OpenTelemetry proto updates automatically
- New OTLP features (logs, profiles) work immediately
- Community support and tools

### 5. **Interoperability**
```
RAK Agents (Rust)
    â””â”€> rak-ingest
    
Other Apps (Go/Python/etc.)
    â””â”€> rak-ingest  âœ… Works!
    
OpenTelemetry Collector
    â””â”€> rak-ingest  âœ… Works!
```

---

## ğŸ”„ Data Flow Simplified

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. RAK Agent generates spans                   â”‚
â”‚     (using rak-telemetry crate)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ OTLP/gRPC (Protobuf)
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. rak-ingest receives ExportTraceServiceRequestâ”‚
â”‚     (auto-generated protobuf message)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ extract resource_spans
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Converter transforms:                       â”‚
â”‚     ResourceSpans -> Vec<Span>                  â”‚
â”‚     (OTLP format -> our internal format)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Batch Buffer accumulates spans              â”‚
â”‚     (in-memory, flushes every 10s or 1000 items)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. ClickHouse Storage writes batch             â”‚
â”‚     INSERT INTO spans VALUES (...)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Dependencies Comparison

### Before (Complex)
```toml
opentelemetry-proto = "0.4"
tonic = "0.10"
prost = "0.12"
axum = "0.7"           # For HTTP endpoints
hyper = "1.0"          # HTTP server
tower = "0.4"          # Middleware
# ... many more
```

### After (Simplified)
```toml
opentelemetry-proto = { version = "0.4", features = ["gen-tonic"] }
tonic = "0.10"
clickhouse = "0.11"
tokio = { version = "1.35", features = ["full"] }
# Done! Much simpler.
```

---

## ğŸš€ Quick Start

### 1. Start ClickHouse
```bash
docker run -d \
  -p 8123:8123 \
  -p 9000:9000 \
  --name clickhouse \
  clickhouse/clickhouse-server
```

### 2. Create Schema
```bash
clickhouse-client < schema.sql
```

### 3. Build & Run rak-ingest
```bash
cd crates/rak-ingest
cargo build --release
./target/release/rak-ingest
```

### 4. Configure RAK Agent
```toml
[telemetry.tracing.otlp]
endpoint = "http://localhost:4317"
```

### 5. Done!
All telemetry automatically flows to ClickHouse.

---

## ğŸ§ª Testing

### Test with opentelemetry-collector

You can test `rak-ingest` using the official OpenTelemetry Collector:

```yaml
# collector-config.yaml
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4316

exporters:
  otlp:
    endpoint: localhost:4317  # rak-ingest
    tls:
      insecure: true

service:
  pipelines:
    traces:
      receivers: [otlp]
      exporters: [otlp]
```

```bash
otelcol --config collector-config.yaml
```

Now send traces to collector (port 4316), they'll be forwarded to rak-ingest (port 4317).

---

## ğŸ“Š Performance

Same as before:
- **Ingestion**: ~50K spans/sec (single instance)
- **Latency**: < 10ms per request
- **Storage**: ~5.6 GB/day compressed (1000 agents)

But with simpler code = easier to optimize!

---

## âœ… Updated Implementation Checklist

### Phase 1: Core (Week 1)
- [x] Add `opentelemetry-proto` dependency with `gen-tonic` feature
- [ ] Implement `TraceService` trait
- [ ] Implement `MetricsService` trait
- [ ] Create OTLP converter (protobuf -> internal format)
- [ ] Test with sample OTLP data

### Phase 2: Storage (Week 1-2)
- [ ] ClickHouse client (same as before)
- [ ] Batch buffer (same as before)
- [ ] Background flusher (same as before)
- [ ] Test end-to-end flow

### Phase 3: Production (Week 2-3)
- [ ] Error handling and retries
- [ ] Metrics/monitoring
- [ ] Docker image
- [ ] Deploy and test

**Total**: ~2-3 weeks (vs 5 weeks before)

---

## ğŸ¯ Key Changes Summary

| Aspect | Before (Complex) | After (Simplified) |
|--------|------------------|-------------------|
| **Protocols** | OTLP gRPC + HTTP + pprof | OTLP gRPC only |
| **Ports** | 4317, 4318, 4319 | 4317 (standard) |
| **Code** | Custom handlers | Implement traits |
| **Lines** | ~2500 | ~800 |
| **Dependencies** | 15+ crates | 5 core crates |
| **Maintenance** | High (custom code) | Low (proto-driven) |
| **Compatibility** | Rust only | Any OTLP client |
| **Timeline** | 5 weeks | 2-3 weeks |

---

## ğŸ“ What About pprof/Profiles?

**Option 1**: Convert profiles to OTLP format
- OpenTelemetry is adding profiling support
- Wait for standard, then implement

**Option 2**: Keep pprof endpoint separate (small addition)
```rust
// Add a simple HTTP endpoint for pprof
async fn handle_pprof(body: Bytes) -> Result<(), Status> {
    // Decode pprof, store in ClickHouse
}
```

**Recommendation**: Start with traces & metrics (OTLP), add profiles later as needed.

---

## ğŸ‰ Conclusion

By using OpenTelemetry's official proto definitions:

âœ… **70% less code** (800 vs 2500 lines)  
âœ… **50% faster to implement** (2-3 vs 5 weeks)  
âœ… **100% standard compliance** (works with any OTLP client)  
âœ… **Future-proof** (proto updates automatic)  
âœ… **Easier to maintain** (trait implementation only)  

**This is the right approach!** ğŸš€

Let me know if you want to see any specific part in more detail!

